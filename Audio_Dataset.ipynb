{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10972600,"sourceType":"datasetVersion","datasetId":6827640}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T06:02:44.133292Z","iopub.execute_input":"2025-03-08T06:02:44.133620Z","iopub.status.idle":"2025-03-08T06:02:45.852519Z","shell.execute_reply.started":"2025-03-08T06:02:44.133585Z","shell.execute_reply":"2025-03-08T06:02:45.851311Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Install dependencies\n!pip install pydub\n!apt-get update\n!apt-get install -y ffmpeg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:26:37.028559Z","iopub.execute_input":"2025-03-09T17:26:37.028931Z","iopub.status.idle":"2025-03-09T17:26:51.091526Z","shell.execute_reply.started":"2025-03-09T17:26:37.028886Z","shell.execute_reply":"2025-03-09T17:26:51.090465Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\nHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]                \nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                           \nHit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease                        \nHit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease  \nHit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease    \nGet:9 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nGet:10 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [68.9 kB]      \nGet:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,369 kB]\nGet:12 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,988 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,934 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [64.2 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [56.4 kB]\nGet:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,235 kB]\nGet:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,668 kB]\nGet:21 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,774 kB]\nGet:22 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,682 kB]         \nGet:23 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,731 kB]                \nFetched 29.5 MB in 3s (9,077 kB/s)                           \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 151 not upgraded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import requests\nimport datetime\nimport time\nimport os\nimport json\nimport threading\nimport random\nfrom pydub import AudioSegment\n\nclass RadioRecorder:\n    def __init__(self, output_dir=\"recordings\"):\n        \"\"\"Initialize the recorder with an output directory.\"\"\"\n        self.output_dir = output_dir\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        \n        # Sample radio stations with stream URLs\n        self.radio_stations = {\n            \"NPR\": \"https://npr-ice.streamguys1.com/live.mp3\",\n            \"BBC_World_Service\": \"http://stream.live.vc.bbcmedia.co.uk/bbc_world_service\",\n            \"KEXP\": \"https://kexp.streamguys1.com/kexp160.aac\",\n            \"WNYC\": \"https://fm939.wnyc.org/wnycfm\",\n            \"RED_FM\" : \"https://funasia.streamguys1.com/live9\",\n            \"BIG_CITY\" : \"https://prclive4.listenon.in/Hindi\"\n        }\n        \n        self.metadata_file = os.path.join(output_dir, \"recordings_metadata.json\")\n        self.load_metadata()\n        \n    def load_metadata(self):\n        \"\"\"Load existing metadata if it exists.\"\"\"\n        if os.path.exists(self.metadata_file):\n            with open(self.metadata_file, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.metadata = []\n            \n    def save_metadata(self):\n        \"\"\"Save metadata to file.\"\"\"\n        with open(self.metadata_file, 'w') as f:\n            json.dump(self.metadata, f, indent=4)\n            \n    def record_stream(self, station_name, duration=30, file_format=\"mp3\"):\n        \"\"\"\n        Record a stream for a specified duration.\n        \n        Args:\n            station_name: Name of the radio station to record\n            duration: Duration in seconds to record\n            file_format: Output file format (mp3 or wav)\n        \n        Returns:\n            Path to the recorded file\n        \"\"\"\n        if station_name not in self.radio_stations:\n            print(f\"Station {station_name} not found in available stations\")\n            return None\n            \n        stream_url = self.radio_stations[station_name]\n        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"{station_name}_{timestamp}.{file_format}\"\n        filepath = os.path.join(self.output_dir, filename)\n        \n        try:\n            # Start streaming and save to file\n            print(f\"Recording {station_name} for {duration} seconds...\")\n            \n            # Stream chunk by chunk to handle large streams\n            response = requests.get(stream_url, stream=True)\n            with open(f\"{filepath}.temp\", 'wb') as f:\n                start_time = time.time()\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n                    # Check if we've recorded long enough\n                    if time.time() - start_time >= duration:\n                        break\n            \n            # Convert temp file to desired format using pydub\n            audio = AudioSegment.from_file(f\"{filepath}.temp\")\n            # Trim to exact duration\n            audio = audio[:duration * 1000]  # pydub works in milliseconds\n            \n            if file_format.lower() == \"mp3\":\n                audio.export(filepath, format=\"mp3\")\n            else:\n                audio.export(filepath, format=\"wav\")\n                \n            # Clean up temp file\n            os.remove(f\"{filepath}.temp\")\n            \n            # Record metadata\n            recording_metadata = {\n                \"station\": station_name,\n                \"timestamp\": timestamp,\n                \"duration\": duration,\n                \"format\": file_format,\n                \"filename\": filename,\n                \"stream_url\": stream_url\n            }\n            \n            self.metadata.append(recording_metadata)\n            self.save_metadata()\n            \n            print(f\"Successfully recorded {station_name} to {filepath}\")\n            return filepath\n            \n        except Exception as e:\n            print(f\"Error recording {station_name}: {e}\")\n            return None\n    \n    def record_multiple(self, count=30, duration_range=(30, 90), formats=[\"mp3\"]):\n        \"\"\"\n        Record multiple stations randomly.\n        \n        Args:\n            count: Number of recordings to make\n            duration_range: Tuple of (min_duration, max_duration) in seconds\n            formats: List of formats to use (randomly selected)\n        \"\"\"\n        stations = list(self.radio_stations.keys())\n        successful_recordings = 0\n        \n        while successful_recordings < count:\n            station = random.choice(stations)\n            duration = random.randint(duration_range[0], duration_range[1])\n            file_format = random.choice(formats)\n            \n            print(f\"Recording {successful_recordings+1}/{count}: {station} for {duration}s\")\n            result = self.record_stream(station, duration, file_format)\n            \n            if result:\n                successful_recordings += 1\n                # Add a small delay between recordings\n                time.sleep(2)\n    \n    def get_indian_stations(self):\n        \"\"\"Return list of available Indian radio stations.\"\"\"\n        indian_stations = [\n            \"AIR_FM_Gold\", \"AIR_Vividh_Bharati\", \"Radio_Mirchi_98.3\", \n            \"Radio_City\", \"Red_FM\", \"Big_FM\", \"Fever_104_FM\", \n            \"Radio_One_India\", \"Radio_Indigo\", \"AIR_FM_Rainbow\"\n        ]\n        return [station for station in indian_stations if station in self.radio_stations]\n    \n    def record_from_country(self, country=\"india\", count=10, duration_range=(30, 90), formats=[\"mp3\"]):\n        \"\"\"\n        Record multiple stations from a specific country.\n        \n        Args:\n            country: Country name (currently only \"india\" is supported)\n            count: Number of recordings to make\n            duration_range: Tuple of (min_duration, max_duration) in seconds\n            formats: List of formats to use (randomly selected)\n        \"\"\"\n        if country.lower() == \"india\":\n            stations = self.get_indian_stations()\n        else:\n            print(f\"Country {country} not explicitly supported, using all stations\")\n            stations = list(self.radio_stations.keys())\n            \n        successful_recordings = 0\n        \n        while successful_recordings < count and stations:\n            station = random.choice(stations)\n            duration = random.randint(duration_range[0], duration_range[1])\n            file_format = random.choice(formats)\n            \n            print(f\"Recording {successful_recordings+1}/{count}: {station} for {duration}s\")\n            result = self.record_stream(station, duration, file_format)\n            \n            if result:\n                successful_recordings += 1\n                # Add a small delay between recordings\n                time.sleep(2)\n\n# Create a function that can be called directly from the notebook\ndef record_radio_stations(output_dir=\"/kaggle/working/recordings\", \n                          count=30, \n                          min_duration=30, \n                          max_duration=90, \n                          formats=\"mp3,wav\", \n                          country=None):\n    \"\"\"\n    Main function to record radio stations.\n    \n    Args:\n        output_dir: Directory to save recordings\n        count: Number of recordings to make\n        min_duration: Minimum recording duration in seconds\n        max_duration: Maximum recording duration in seconds\n        formats: Comma-separated string of formats\n        country: Record from specific country (e.g., \"india\")\n    \"\"\"\n    format_list = formats.split(',')\n    \n    recorder = RadioRecorder(output_dir=output_dir)\n    \n    if country:\n        recorder.record_from_country(\n            country=country,\n            count=count,\n            duration_range=(min_duration, max_duration),\n            formats=format_list\n        )\n    else:\n        recorder.record_multiple(\n            count=count,\n            duration_range=(min_duration, max_duration),\n            formats=format_list\n        )\n    \n    print(f\"Completed recording {count} audio files.\")\n    print(f\"Metadata saved to {recorder.metadata_file}\")\n    \n    # Create a zip file for easy download from Kaggle\n    try:\n        import shutil\n        zip_path = os.path.join(os.path.dirname(output_dir), \"recordings.zip\")\n        shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', output_dir)\n        print(f\"Created zip archive at {zip_path}\")\n    except Exception as e:\n        print(f\"Could not create zip archive: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:57:07.808919Z","iopub.execute_input":"2025-03-09T05:57:07.809316Z","iopub.status.idle":"2025-03-09T05:57:07.831527Z","shell.execute_reply.started":"2025-03-09T05:57:07.809283Z","shell.execute_reply":"2025-03-09T05:57:07.830485Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Install dependencies\n!pip install requests pydub\n!apt-get update && apt-get install -y ffmpeg\n\n# Copy the script code into a cell and run it\n# (Copy the entire code from the artifact above)\n\n# Now use the function directly\nrecord_radio_stations(\n    output_dir=\"/kaggle/working/recordings\",\n    count=30,\n    min_duration=30,\n    max_duration=90,\n    formats=\"mp3\",\n    country=None  # Set to None for all stations\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:58:01.713436Z","iopub.execute_input":"2025-03-09T05:58:01.713822Z","iopub.status.idle":"2025-03-09T06:29:19.803140Z","shell.execute_reply.started":"2025-03-09T05:58:01.713790Z","shell.execute_reply":"2025-03-09T06:29:19.801827Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [68.9 kB]                 \nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nGet:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,369 kB]\nHit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease                        \nGet:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,730 kB]                      \nHit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease                 \nHit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease                        \nGet:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\nGet:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,668 kB]\nGet:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [56.4 kB]\nGet:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,774 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [64.2 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,988 kB]         \nGet:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,682 kB]         \nGet:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,235 kB]     \nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,934 kB]       \nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nFetched 29.5 MB in 3s (9,056 kB/s)                           \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 151 not upgraded.\nRecording 1/30: RED_FM for 61s\nRecording RED_FM for 61 seconds...\nSuccessfully recorded RED_FM to /kaggle/working/recordings/RED_FM_20250309_055816.mp3\nRecording 2/30: RED_FM for 48s\nRecording RED_FM for 48 seconds...\nSuccessfully recorded RED_FM to /kaggle/working/recordings/RED_FM_20250309_055923.mp3\nRecording 3/30: KEXP for 74s\nRecording KEXP for 74 seconds...\nSuccessfully recorded KEXP to /kaggle/working/recordings/KEXP_20250309_060016.mp3\nRecording 4/30: BIG_CITY for 45s\nRecording BIG_CITY for 45 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_060136.mp3\nRecording 5/30: WNYC for 88s\nRecording WNYC for 88 seconds...\nSuccessfully recorded WNYC to /kaggle/working/recordings/WNYC_20250309_060226.mp3\nRecording 6/30: NPR for 41s\nRecording NPR for 41 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_060359.mp3\nRecording 7/30: WNYC for 84s\nRecording WNYC for 84 seconds...\nSuccessfully recorded WNYC to /kaggle/working/recordings/WNYC_20250309_060443.mp3\nRecording 8/30: NPR for 67s\nRecording NPR for 67 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_060612.mp3\nRecording 9/30: NPR for 81s\nRecording NPR for 81 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_060724.mp3\nRecording 10/30: BIG_CITY for 38s\nRecording BIG_CITY for 38 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_060849.mp3\nRecording 11/30: WNYC for 84s\nRecording WNYC for 84 seconds...\nSuccessfully recorded WNYC to /kaggle/working/recordings/WNYC_20250309_060932.mp3\nRecording 12/30: NPR for 36s\nRecording NPR for 36 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_061101.mp3\nRecording 13/30: BBC_World_Service for 42s\nRecording BBC_World_Service for 42 seconds...\nSuccessfully recorded BBC_World_Service to /kaggle/working/recordings/BBC_World_Service_20250309_061142.mp3\nRecording 14/30: BIG_CITY for 38s\nRecording BIG_CITY for 38 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_061229.mp3\nRecording 15/30: BBC_World_Service for 80s\nRecording BBC_World_Service for 80 seconds...\nSuccessfully recorded BBC_World_Service to /kaggle/working/recordings/BBC_World_Service_20250309_061312.mp3\nRecording 16/30: BIG_CITY for 42s\nRecording BIG_CITY for 42 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_061437.mp3\nRecording 17/30: KEXP for 46s\nRecording KEXP for 46 seconds...\nSuccessfully recorded KEXP to /kaggle/working/recordings/KEXP_20250309_061524.mp3\nRecording 18/30: BIG_CITY for 31s\nRecording BIG_CITY for 31 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_061615.mp3\nRecording 19/30: NPR for 30s\nRecording NPR for 30 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_061651.mp3\nRecording 20/30: BIG_CITY for 86s\nRecording BIG_CITY for 86 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_061725.mp3\nRecording 21/30: BIG_CITY for 78s\nRecording BIG_CITY for 78 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_061857.mp3\nRecording 22/30: BIG_CITY for 52s\nRecording BIG_CITY for 52 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_062022.mp3\nRecording 23/30: RED_FM for 66s\nRecording RED_FM for 66 seconds...\nSuccessfully recorded RED_FM to /kaggle/working/recordings/RED_FM_20250309_062119.mp3\nRecording 24/30: BBC_World_Service for 49s\nRecording BBC_World_Service for 49 seconds...\nSuccessfully recorded BBC_World_Service to /kaggle/working/recordings/BBC_World_Service_20250309_062231.mp3\nRecording 25/30: NPR for 44s\nRecording NPR for 44 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_062325.mp3\nRecording 26/30: NPR for 83s\nRecording NPR for 83 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_062413.mp3\nRecording 27/30: BIG_CITY for 51s\nRecording BIG_CITY for 51 seconds...\nSuccessfully recorded BIG_CITY to /kaggle/working/recordings/BIG_CITY_20250309_062541.mp3\nRecording 28/30: NPR for 82s\nRecording NPR for 82 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_062637.mp3\nRecording 29/30: WNYC for 31s\nRecording WNYC for 31 seconds...\nSuccessfully recorded WNYC to /kaggle/working/recordings/WNYC_20250309_062804.mp3\nRecording 30/30: NPR for 36s\nRecording NPR for 36 seconds...\nSuccessfully recorded NPR to /kaggle/working/recordings/NPR_20250309_062838.mp3\nCompleted recording 30 audio files.\nMetadata saved to /kaggle/working/recordings/recordings_metadata.json\nCreated zip archive at /kaggle/working/recordings.zip\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## We can use this dataset as a test dataset for an automatic speech recognition (ASR) model","metadata":{}},{"cell_type":"code","source":"# !pip install openai-whisper ffmpeg\n# !apt-get update && apt-get install -y ffmpeg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:02:06.761540Z","iopub.execute_input":"2025-03-09T18:02:06.762023Z","iopub.status.idle":"2025-03-09T18:02:06.765715Z","shell.execute_reply.started":"2025-03-09T18:02:06.761996Z","shell.execute_reply":"2025-03-09T18:02:06.764852Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import whisper\nimport os\nfrom pathlib import Path\n\n# Load Whisper model (Use 'medium' or 'large' for better accuracy)\nmodel = whisper.load_model(\"medium\", device=\"cuda\")  # GPU enabled\n\n# Path to the uploaded audio dataset in Kaggle\naudio_folder = \"/kaggle/input/recordings/Final_recordings\"\noutput_folder = \"/kaggle/working/transcripts\"\n\n# Create output folder\nos.makedirs(output_folder, exist_ok=True)\n\n# Process each audio file\nfor file_path in Path(audio_folder).glob(\"*\"):\n    if file_path.suffix in [\".mp3\", \".wav\", \".m4a\", \".flac\"]:\n        print(f\"Transcribing: {file_path.name}...\")\n\n        # Transcribe audio\n        result = model.transcribe(str(file_path))\n\n        # Save transcript\n        transcript_path = os.path.join(output_folder, f\"{file_path.stem}.txt\")\n        with open(transcript_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(result[\"text\"])\n\n        print(f\"Saved: {transcript_path}\")\n\nprint(\"✅ Transcription complete! Transcripts are saved in /kaggle/working/transcripts\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:51:22.487989Z","iopub.execute_input":"2025-03-09T17:51:22.488394Z","iopub.status.idle":"2025-03-09T18:02:06.760404Z","shell.execute_reply.started":"2025-03-09T17:51:22.488364Z","shell.execute_reply":"2025-03-09T18:02:06.759492Z"}},"outputs":[{"name":"stderr","text":"100%|█████████████████████████████████████| 1.42G/1.42G [00:20<00:00, 74.5MiB/s]\n/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Transcribing: BIG_CITY_20250309_062022.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_062022.txt\nTranscribing: NPR_20250309_062413.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_062413.txt\nTranscribing: NPR_20250309_061101.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_061101.txt\nTranscribing: BIG_CITY_20250309_061437.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_061437.txt\nTranscribing: WNYC_20250309_060226.mp3...\nSaved: /kaggle/working/transcripts/WNYC_20250309_060226.txt\nTranscribing: NPR_20250309_062838.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_062838.txt\nTranscribing: BIG_CITY_20250309_061725.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_061725.txt\nTranscribing: WNYC_20250309_060443.mp3...\nSaved: /kaggle/working/transcripts/WNYC_20250309_060443.txt\nTranscribing: BIG_CITY_20250309_060849.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_060849.txt\nTranscribing: NPR_20250309_061651.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_061651.txt\nTranscribing: BIG_CITY_20250309_061615.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_061615.txt\nTranscribing: WNYC_20250309_060932.mp3...\nSaved: /kaggle/working/transcripts/WNYC_20250309_060932.txt\nTranscribing: BIG_CITY_20250309_062541.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_062541.txt\nTranscribing: WNYC_20250309_062804.mp3...\nSaved: /kaggle/working/transcripts/WNYC_20250309_062804.txt\nTranscribing: BIG_CITY_20250309_061229.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_061229.txt\nTranscribing: NPR_20250309_062325.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_062325.txt\nTranscribing: BIG_CITY_20250309_061857.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_061857.txt\nTranscribing: NPR_20250309_062637.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_062637.txt\nTranscribing: NPR_20250309_060359.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_060359.txt\nTranscribing: BBC_World_Service_20250309_061142.mp3...\nSaved: /kaggle/working/transcripts/BBC_World_Service_20250309_061142.txt\nTranscribing: BIG_CITY_20250309_060136.mp3...\nSaved: /kaggle/working/transcripts/BIG_CITY_20250309_060136.txt\nTranscribing: RED_FM_20250309_055923.mp3...\nSaved: /kaggle/working/transcripts/RED_FM_20250309_055923.txt\nTranscribing: BBC_World_Service_20250309_062231.mp3...\nSaved: /kaggle/working/transcripts/BBC_World_Service_20250309_062231.txt\nTranscribing: RED_FM_20250309_062119.mp3...\nSaved: /kaggle/working/transcripts/RED_FM_20250309_062119.txt\nTranscribing: NPR_20250309_060612.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_060612.txt\nTranscribing: NPR_20250309_060724.mp3...\nSaved: /kaggle/working/transcripts/NPR_20250309_060724.txt\nTranscribing: KEXP_20250309_060016.mp3...\nSaved: /kaggle/working/transcripts/KEXP_20250309_060016.txt\nTranscribing: RED_FM_20250309_055816.mp3...\nSaved: /kaggle/working/transcripts/RED_FM_20250309_055816.txt\nTranscribing: BBC_World_Service_20250309_061312.mp3...\nSaved: /kaggle/working/transcripts/BBC_World_Service_20250309_061312.txt\nTranscribing: KEXP_20250309_061524.mp3...\nSaved: /kaggle/working/transcripts/KEXP_20250309_061524.txt\n✅ Transcription complete! Transcripts are saved in /kaggle/working/transcripts\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}